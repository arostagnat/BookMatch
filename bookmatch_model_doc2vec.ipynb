{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "fa214fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "bb866261",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import metadata\n",
    "\n",
    "book_metadata_url = \"/Users/egmac/code/arostagnat/raw_data/raw_book/metadata\"\n",
    "movie_metadata_url = \"/Users/egmac/code/arostagnat/raw_data/raw_movies/metadata\"\n",
    "\n",
    "book_details = pd.read_json(book_metadata_url+\".json\",lines=True)\n",
    "movie_details = pd.read_json(film_metadata_url+\".json\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17287d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data. Make sure to replace sample data with full data when available\n",
    "book_URL = '/Users/egmac/code/arostagnat/raw_data/sample_books_reviews_clean.csv'\n",
    "movie_URL = '/Users/egmac/code/arostagnbat/raw_data/sample_movies_reviews_clean.csv'\n",
    "book_data = pd.read_csv(book_URL,names=[\"index\",\"item_id\",\"txt\"],header=0,index_col=\"index\",usecols=[\"index\",\"item_id\",\"txt\"])\n",
    "movie_data = pd.read_csv(movies_URL,names=[\"index\",\"item_id\",\"txt\"],header=0,index_col=\"index\",usecols=[\"index\",\"item_id\",\"txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a5f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set tag for book / movie\n",
    "book_data[\"type\"] = 1\n",
    "movie_data[\"type\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aab732",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate book and movies data\n",
    "data = pd.concat([movie_data,book_data])\n",
    "data = data.reset_index()\n",
    "data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b977be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# book_data.head()\n",
    "# movie_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7768704",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up training and test datasets\n",
    "data_train, data_test = train_test_split(data,test_size=0.2)\n",
    "print(f\"data_train: {data_train.shape}, data_test: {data_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0778fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reset index to match document tagging\n",
    "data_train_copy = data_train.copy()\n",
    "data_train_copy = data_train_copy.reset_index()\n",
    "data_train_copy.index.name = \"new_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf03c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add required tagging\n",
    "data_train_tag = [TaggedDocument(doc, [i]) for i, doc in enumerate(data_train[\"txt\"])]\n",
    "print(f\"data_train_tag: {len(data_train_tag)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e1eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup Doc2Vec model\n",
    "model = Doc2Vec(vector_size=50, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build vocab\n",
    "model.build_vocab(data_train_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a26cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train model\n",
    "model.train(data_train_tag,epochs=50,word_count=0,total_examples=model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b7e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confirm output of txt column\n",
    "print(data.loc[1][\"txt\"])\n",
    "type(data.loc[1][\"txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a207150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtain inferred vectors for each film / book\n",
    "vectors_list = []\n",
    "\n",
    "for i in data_train.index:\n",
    "    text = data_train.loc[i][\"txt\"]\n",
    "    text_cleaned = text.strip('[]').replace(\"'\",\"\").replace(' ', '').split(',')\n",
    "    inferred_vector = model.infer_vector(text_cleaned)\n",
    "    vectors_list.append(inferred_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ab6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add vectors to data_train\n",
    "data_train[\"vector\"] = vectors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cb2f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "0a04d65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtain top 10 similar items for each film / book\n",
    "top_book_dict = {}\n",
    "\n",
    "for i in data_train.index[:20]:\n",
    "    vector = data_train.loc[i][\"vector\"]\n",
    "    similar_items = model.dv.most_similar([vector],topn=1000)\n",
    "    results = pd.DataFrame(similar_items,columns=[\"new_index\",\"cosine\"]).set_index(\"new_index\")\n",
    "    results = results.merge(data_train_copy[[\"item_id\",\"type\"]],how=\"left\",on=\"new_index\")\n",
    "    results_copy = results[results.type == 1].sort_values(by=[\"cosine\"],ascending=False).reset_index()\n",
    "    top_book_dict[i] = results_copy.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f171642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add top books and cosines to data_train\n",
    "\n",
    "top_books = [top_book_dict[i][\"item_id\"] for i in data_train.index]\n",
    "top_cosine = [top_book_dict[i][\"cosine\"] for i in data_train.index]\n",
    "\n",
    "data_train[\"top_book\"] = top_books\n",
    "data_train[\"cosine\"] = top_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad2431",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.loc[movie_index][\"item_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "ce35f4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_c/hnby49996jgf113yx9b06pd80000gn/T/ipykernel_16009/578020551.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_train_films.item_id = data_train_films.item_id.astype(int)\n"
     ]
    }
   ],
   "source": [
    "data_train_films = data_train[data_train.type == 0]\n",
    "data_train_films.item_id = data_train_films.item_id.astype(int)\n",
    "movie_details.item_id = movie_details.item_id.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "c3c69010",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_films = data_train_films.merge(movie_details[[\"title\",\"item_id\"]],how=\"left\",on=\"item_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "4f42f8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484       4896\n",
       "670      54001\n",
       "770       5816\n",
       "1244     40815\n",
       "1757     54001\n",
       "         ...  \n",
       "42441     5816\n",
       "42787     8368\n",
       "42824     8368\n",
       "42835    69844\n",
       "42900    88125\n",
       "Name: item_id, Length: 163, dtype: int64"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword = \"potter\"\n",
    "data_train_films[data_train_films[\"title\"].str.contains(keyword,case=False,na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "58426cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define formula to provide recommendations for random vectors\n",
    "\n",
    "def get_book_recc(movie_id):\n",
    "    \n",
    "    movie_index = data_train[data_train[\"item_id\"] == movie_id].index[0]\n",
    "    \n",
    "    text = data_train.loc[movie_index][\"txt\"]\n",
    "    text_cleaned = text.strip('[]').replace(\"'\",\"\").replace(' ', '').split(',')\n",
    "    \n",
    "    inferred_vector = model.infer_vector(text_cleaned)\n",
    "    similar_items = model.dv.most_similar([inferred_vector], topn=1000)\n",
    "    \n",
    "    results = pd.DataFrame(similar_items,columns=[\"new_index\",\"cosine\"]).set_index(\"new_index\")\n",
    "    results = results.merge(data_train_copy[[\"item_id\",\"type\"]],how=\"left\",on=\"new_index\")\n",
    "    results_copy = results[results.type == 1].sort_values(by=[\"cosine\"],ascending=False).reset_index()\n",
    "    book_id_1 = results_copy.loc[0][\"item_id\"]\n",
    "    book_id_2 = results_copy.loc[1][\"item_id\"]\n",
    "    book_id_3 = results_copy.loc[2][\"item_id\"]\n",
    "    \n",
    "    movie_name = movie_details[movie_details[\"item_id\"]==movie_id][\"title\"].to_string()\n",
    "    book_1_name = book_details[book_details[\"item_id\"]==book_id_1][\"title\"].to_string()\n",
    "    book_2_name = book_details[book_details[\"item_id\"]==book_id_2][\"title\"].to_string()\n",
    "    book_3_name = book_details[book_details[\"item_id\"]==book_id_3][\"title\"].to_string()\n",
    "    \n",
    "    print(f\"\"\"Film: {movie_name} \n",
    "    \\\n",
    "    \\\n",
    "    \\\n",
    "    ==== Book recommendations ====\n",
    "    1. {book_1_name}\n",
    "    2. {book_2_name}\n",
    "    3. {book_3_name}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "ff95b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"potter\"\n",
    "sample = data_train_films[data_train_films[\"title\"].str.contains(keyword,case=False,na=False)].item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "b35c2778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Film: 12005    Harry Potter and the Order of the Phoenix (2007) \n",
      "                ==== Book recommendations ====\n",
      "    1. 2244    Maus II: A Survivor's Tale: And Here My Troubl...\n",
      "    2. 32    The Alchemist\n",
      "    3. 2543    The 4-Hour Workweek\n",
      "Film: 10623    Harry Potter and the Goblet of Fire (2005) \n",
      "                ==== Book recommendations ====\n",
      "    1. 2952    My Sister's Grave (Tracy Crosswhite, #1)\n",
      "    2. 547    Through the Woods\n",
      "    3. 2524    Still Life with Bread Crumbs\n",
      "Film: 13988    Harry Potter and the Half-Blood Prince (2009) \n",
      "                ==== Book recommendations ====\n",
      "    1. 5913    Confessions of a Prairie Bitch: How I Survived...\n",
      "    2. 220    Wicked: The Life and Times of the Wicked Witch...\n",
      "    3. 5502    Save the Cat!: The Last Book on Screenwriting ...\n",
      "Film: 5718    Harry Potter and the Chamber of Secrets (2002) \n",
      "                ==== Book recommendations ====\n",
      "    1. 2128    Meant to Be\n",
      "    2. 1143    Fracture Me (Shatter Me, #2.5)\n",
      "    3. 295    Dracula\n"
     ]
    }
   ],
   "source": [
    "potter = [54001,40815,69844,5816]\n",
    "\n",
    "for item in potter:\n",
    "    get_book_recc(movie_id=item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
