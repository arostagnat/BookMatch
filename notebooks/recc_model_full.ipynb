{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load cleaned data\n",
    "X_all = pd.read_csv(\"/Users/egmac/code/arostagnat/BookMatch/data/proc_data/cluster_result/X_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61455, 8)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import book ratings for recommendation filtering\n",
    "ratings_books =  pd.read_json(\"/Users/egmac/code/arostagnat/BookMatch/data/raw_data/raw_book/ratings.json\", lines=True)\n",
    "ratings_books = ratings_books.rename(columns={\"item_id\":\"item_id_book\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ratings df: (5152656, 3) | Average ratings df: (9374, 1)\n"
     ]
    }
   ],
   "source": [
    "## Calculate average rating for each book\n",
    "avg_ratings_books = ratings_books.groupby([\"item_id_book\"]).mean().drop(columns=[\"user_id\"])\n",
    "print(f\"Original ratings df: {ratings_books.shape} | Average ratings df: {avg_ratings_books.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import relevant packages\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create extract of X_all with vectors spread across columns, and confirm relevance of dimensions\n",
    "## Vectors have to be reformatted as lists, as they are formatted as strings with \"\"\n",
    "\n",
    "vectors = X_all.vector.tolist()\n",
    "vectors_revised = []\n",
    "\n",
    "for vector in vectors:\n",
    "    result = vector.strip('[]').replace(\"'\",\"\").replace(\"\\n\",\"\").split()\n",
    "    result = [float(i) for i in result]\n",
    "    vectors_revised.append(result)\n",
    "\n",
    "X_vectors = pd.DataFrame(vectors_revised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd = TruncatedSVD(n_components=X_vectors.shape[1])\n",
    "# svd_result = svd.fit_transform(X_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot variance as a function of the number of components.\n",
    "## Based on the below figure, nearly 100% of the variance is explained by 250 components\n",
    "# plt.plot(svd.explained_variance_ratio_.cumsum())\n",
    "# plt.xlabel('Number of singular value components')\n",
    "# plt.ylabel('Cumulative percent of variance')   \n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshape vectors to 250 components, which will help reduce computational time\n",
    "# n = 250\n",
    "# X_vectors_revised = pd.DataFrame(X_vectors.iloc[:,0:n])\n",
    "# print(f'X_all shape: {X_all.shape} | X_vectors shape: {X_vectors.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add qualitative columns to X_vectors_revised, and then create 2 separate dataframes for books and movies.\n",
    "## Movie dataframe to be used to lookup user-inputted movies. Book dataframe to be used for calculations.\n",
    "## Note that the dataframes need to be separated eventually, so it's worth doing now.\n",
    "\n",
    "X_vectors[[\"item_id_movie\",\"item_id_book\",\"is_movie\",\"clustering_label_bert\"]] = X_all[[\"item_id_movie\",\"item_id_book\",\"is_movie\",\"clustering_label_bert\"]]\n",
    "X_vectors_movies = X_vectors[X_vectors.is_movie == 1].set_index(\"item_id_movie\",drop=True).drop(columns=[\"item_id_book\",\"is_movie\"])\n",
    "X_vectors_books = X_vectors[X_vectors.is_movie == 0].set_index(\"item_id_book\",drop=True).drop(columns=[\"item_id_movie\",\"is_movie\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_c/hnby49996jgf113yx9b06pd80000gn/T/ipykernel_58454/3642167841.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_vectors_good_books = pd.merge(X_vectors_books,avg_ratings_books,how=\"left\",on=\"item_id_book\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>clustering_label_bert</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id_book</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49566885.0</th>\n",
       "      <td>-0.067562</td>\n",
       "      <td>-0.013810</td>\n",
       "      <td>0.087461</td>\n",
       "      <td>0.010315</td>\n",
       "      <td>-0.034190</td>\n",
       "      <td>0.044712</td>\n",
       "      <td>-0.042676</td>\n",
       "      <td>-0.003757</td>\n",
       "      <td>-0.019110</td>\n",
       "      <td>-0.066859</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013075</td>\n",
       "      <td>-0.029805</td>\n",
       "      <td>0.044801</td>\n",
       "      <td>-0.076599</td>\n",
       "      <td>0.070121</td>\n",
       "      <td>0.072632</td>\n",
       "      <td>0.016956</td>\n",
       "      <td>-0.016898</td>\n",
       "      <td>-0.009537</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48125855.0</th>\n",
       "      <td>-0.021348</td>\n",
       "      <td>-0.130383</td>\n",
       "      <td>0.065956</td>\n",
       "      <td>0.012416</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.028791</td>\n",
       "      <td>-0.077499</td>\n",
       "      <td>-0.062951</td>\n",
       "      <td>0.042728</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011231</td>\n",
       "      <td>-0.092780</td>\n",
       "      <td>0.053753</td>\n",
       "      <td>-0.033295</td>\n",
       "      <td>0.061573</td>\n",
       "      <td>0.027644</td>\n",
       "      <td>-0.020969</td>\n",
       "      <td>-0.093529</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3         4         5  \\\n",
       "item_id_book                                                               \n",
       "49566885.0   -0.067562 -0.013810  0.087461  0.010315 -0.034190  0.044712   \n",
       "48125855.0   -0.021348 -0.130383  0.065956  0.012416  0.047087  0.028791   \n",
       "\n",
       "                     6         7         8         9  ...       375       376  \\\n",
       "item_id_book                                          ...                       \n",
       "49566885.0   -0.042676 -0.003757 -0.019110 -0.066859  ... -0.013075 -0.029805   \n",
       "48125855.0   -0.077499 -0.062951  0.042728  0.001619  ... -0.011231 -0.092780   \n",
       "\n",
       "                   377       378       379       380       381       382  \\\n",
       "item_id_book                                                               \n",
       "49566885.0    0.044801 -0.076599  0.070121  0.072632  0.016956 -0.016898   \n",
       "48125855.0    0.053753 -0.033295  0.061573  0.027644 -0.020969 -0.093529   \n",
       "\n",
       "                   383  clustering_label_bert  \n",
       "item_id_book                                   \n",
       "49566885.0   -0.009537                   2048  \n",
       "48125855.0    0.010398                    769  \n",
       "\n",
       "[2 rows x 385 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vectors_good_books = pd.merge(X_vectors_books,avg_ratings_books,how=\"left\",on=\"item_id_book\")\n",
    "X_vectors_good_books = X_vectors_good_books[X_vectors_good_books.rating >= 4].drop(columns=[\"rating\"])\n",
    "X_vectors_good_books.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_vectors_books: (9374, 385) | X_vectors_books.ratings:(3945, 385)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_vectors_books: {X_vectors_books.shape} | X_vectors_books.ratings:{X_vectors_good_books.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 1: For each film in user list, calculate the cosine similarity with all books in the cluster\n",
    "## Then, sort the books by their cosine similarity to identify **the** **closest** book for each film\n",
    "## Finally, take the full list of book recommendations and then identify the **top 5 most frequent** books\n",
    "\n",
    "def get_local_reccs(user_movies:list):\n",
    "    \n",
    "    verified_movies = [movie_id for movie_id in user_movies if movie_id in X_all.item_id_movie.tolist()]\n",
    "    \n",
    "    recommendations = pd.DataFrame(columns=[\"similarity\",\"title_book\",\"img_book\",\"url_book\"])\n",
    "    movies = pd.DataFrame(verified_movies,columns=[\"item_id_movie\"])\n",
    "    movies = pd.merge(movies,X_all[[\"title_movie\",\"item_id_movie\"]],on=\"item_id_movie\",how=\"left\")\n",
    "    \n",
    "    for movie_id in verified_movies:\n",
    "\n",
    "        # Obtain vectors for user-inputted film and all books. Clusters are not used for time being\n",
    "        ### movie_cluster = X_vectors_movies[X_vectors_movies.index == movie_id].cluster_bert.values[0]\n",
    "        movie_vector = X_vectors_movies[X_vectors_movies.index == movie_id].drop(columns=[\"clustering_label_bert\"])\n",
    "        books_vectors = X_vectors_books.drop(columns=[\"clustering_label_bert\"])\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        sim_books = cosine_similarity(books_vectors,movie_vector)\n",
    " \n",
    "        # Create summary table of books with their similarity and relevant details\n",
    "        sim_books_detail = pd.DataFrame(sim_books,index=books_vectors.index,columns=[\"similarity\"])\n",
    "        sim_books_detail = sim_books_detail.sort_values(\"similarity\",ascending=False)\n",
    "        sim_books_detail = pd.merge(sim_books_detail,X_all[[\"title_book\",\"item_id_book\"]],\n",
    "                                    on=\"item_id_book\",how=\"left\")\n",
    "\n",
    "        # Add top book to recommendations dataframe\n",
    "        top_book = pd.DataFrame([sim_books_detail.loc[0]])\n",
    "        recommendations = pd.concat([recommendations,top_book],axis=0, ignore_index=True)\n",
    "    \n",
    "    print(\"Inputted films\")\n",
    "    print(movies)\n",
    "    return recommendations[\"title_book\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 2: Calculate the average vector for all films in the user list, and then identify the corresponding cluster\n",
    "## Then,calculate the cosine similarity with all books in the cluster\n",
    "## Finally, sort the books by their cosine similarities and take the **top 5 closest** books\n",
    "\n",
    "def get_global_reccs(user_movies:list):\n",
    "    \n",
    "    verified_movies = [movie_id for movie_id in user_movies if movie_id in X_all.item_id_movie.tolist()]\n",
    "    \n",
    "    ## Collect vectors of all inputted films and calculate average vector\n",
    "    movies_id = pd.DataFrame(verified_movies,columns=[\"item_id_movie\"])\n",
    "    movies_vectors = pd.merge(movies_id,\n",
    "                              X_vectors_movies,\n",
    "                              how=\"left\",\n",
    "                              on=\"item_id_movie\").set_index(\"item_id_movie\").drop(columns=[\"clustering_label_bert\"])\n",
    "    avg_movie_vector = pd.DataFrame([movies_vectors.mean(numeric_only=True)])\n",
    "    books_vectors = X_vectors_books.drop(columns=[\"clustering_label_bert\"])\n",
    "\n",
    "    ## Calculate cosine similarity\n",
    "    sim_books = cosine_similarity(books_vectors,avg_movie_vector)\n",
    "\n",
    "    ## Create summary table of books with their similarity and relevant details\n",
    "    sim_books_detail = pd.DataFrame(sim_books,index=books_vectors.index,columns=[\"similarity\"])\n",
    "    sim_books_detail = sim_books_detail.sort_values(\"similarity\",ascending=False)\n",
    "    sim_books_detail = pd.merge(sim_books_detail,X_all[[\"title_book\",\"item_id_book\"]],on=\"item_id_book\",how=\"left\")\n",
    "    \n",
    "    ## Take top 5 books and show results\n",
    "    recommendations = sim_books_detail.head(5)\n",
    "    movie_titles = pd.merge(movies_id,X_all[[\"title_movie\",\"item_id_movie\"]],how=\"inner\",on=\"item_id_movie\")\n",
    "    print(\"Inputted films\")\n",
    "    print(movie_titles.title_movie)\n",
    "    print (\"Top 5 book recommendations\")\n",
    "    return recommendations[\"title_book\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations with ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_reccs_rating (user_movies:list):\n",
    "    \n",
    "    verified_movies = [movie_id for movie_id in user_movies if movie_id in X_all.item_id_movie.tolist()]\n",
    "    \n",
    "    recommendations = pd.DataFrame(columns=[\"similarity\",\"title_book\",\"img_book\",\"url_book\"])\n",
    "    movies = pd.DataFrame(verified_movies,columns=[\"item_id_movie\"])\n",
    "    movies = pd.merge(movies,X_all[[\"title_movie\",\"item_id_movie\"]],on=\"item_id_movie\",how=\"left\")\n",
    "    \n",
    "    for movie_id in verified_movies:\n",
    "\n",
    "        # Obtain vectors for user-inputted film and all books. Clusters are not used for time being\n",
    "        movie_vector = X_vectors_movies[X_vectors_movies.index == movie_id].drop(columns=[\"clustering_label_bert\"])\n",
    "        books_vectors = X_vectors_good_books.drop(columns=[\"clustering_label_bert\"])\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        sim_books = cosine_similarity(books_vectors,movie_vector)\n",
    " \n",
    "        # Create summary table of books with their similarity and relevant details\n",
    "        sim_books_detail = pd.DataFrame(sim_books,index=books_vectors.index,columns=[\"similarity\"])\n",
    "        sim_books_detail = sim_books_detail.sort_values(\"similarity\",ascending=False)\n",
    "        sim_books_detail = pd.merge(sim_books_detail,X_all[[\"title_book\",\"item_id_book\"]],\n",
    "                                    on=\"item_id_book\",how=\"left\")\n",
    "\n",
    "        # Add top book to recommendations dataframe\n",
    "        top_book = pd.DataFrame([sim_books_detail.loc[0]])\n",
    "        recommendations = pd.concat([recommendations,top_book],axis=0, ignore_index=True)\n",
    "    \n",
    "    print(\"Inputted films\")\n",
    "    print(movies)\n",
    "    return recommendations[\"title_book\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_reccs_rating (user_movies:list):\n",
    "    \n",
    "    verified_movies = [movie_id for movie_id in user_movies if movie_id in X_all.item_id_movie.tolist()]\n",
    "    \n",
    "    ## Collect vectors of all inputted films and calculate average vector\n",
    "    movies_id = pd.DataFrame(verified_movies,columns=[\"item_id_movie\"])\n",
    "    movies_vectors = pd.merge(movies_id,\n",
    "                              X_vectors_movies,\n",
    "                              how=\"left\",\n",
    "                              on=\"item_id_movie\").set_index(\"item_id_movie\").drop(columns=[\"clustering_label_bert\"])\n",
    "    avg_movie_vector = pd.DataFrame([movies_vectors.mean(numeric_only=True)])\n",
    "    books_vectors = X_vectors_good_books.drop(columns=[\"clustering_label_bert\"])\n",
    "\n",
    "    ## Calculate cosine similarity\n",
    "    sim_books = cosine_similarity(books_vectors,avg_movie_vector)\n",
    "\n",
    "    ## Create summary table of books with their similarity and relevant details\n",
    "    sim_books_detail = pd.DataFrame(sim_books,index=books_vectors.index,columns=[\"similarity\"])\n",
    "    sim_books_detail = sim_books_detail.sort_values(\"similarity\",ascending=False)\n",
    "    sim_books_detail = pd.merge(sim_books_detail,X_all[[\"title_book\",\"item_id_book\"]],on=\"item_id_book\",how=\"left\")\n",
    "    \n",
    "    ## Take top 5 books and show results\n",
    "    recommendations = sim_books_detail.head(5)\n",
    "    movie_titles = pd.merge(movies_id,X_all[[\"title_movie\",\"item_id_movie\"]],how=\"inner\",on=\"item_id_movie\")\n",
    "    print(\"Inputted films\")\n",
    "    print(movie_titles.title_movie)\n",
    "    print (\"Top 5 book recommendations\")\n",
    "    return recommendations[\"title_book\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations with clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_reccs_cluster(user_movies:list):\n",
    "    \n",
    "    verified_movies = [movie_id for movie_id in user_movies if movie_id in X_all.item_id_movie.tolist()]\n",
    "    \n",
    "    recommendations = pd.DataFrame(columns=[\"similarity\",\"title_book\",\"img_book\",\"url_book\"])\n",
    "    movies = pd.DataFrame(verified_movies,columns=[\"item_id_movie\"])\n",
    "    movies = pd.merge(movies,X_all[[\"title_movie\",\"item_id_movie\"]],on=\"item_id_movie\",how=\"left\")\n",
    "    \n",
    "    for movie_id in verified_movies:\n",
    "\n",
    "        # Obtain vectors for user-inputted film and all books.\n",
    "        movie_cluster = X_vectors_movies[X_vectors_movies.index == movie_id].clustering_label_bert.values[0]\n",
    "        movie_vector = X_vectors_movies[X_vectors_movies.index == movie_id].drop(columns=[\"clustering_label_bert\"])\n",
    "        books_vectors = X_vectors_books[X_vectors_books.clustering_label_bert == movie_cluster].drop(columns=[\"clustering_label_bert\"])\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        sim_books = cosine_similarity(books_vectors,movie_vector)\n",
    " \n",
    "        # Create summary table of books with their similarity and relevant details\n",
    "        sim_books_detail = pd.DataFrame(sim_books,index=books_vectors.index,columns=[\"similarity\"])\n",
    "        sim_books_detail = sim_books_detail.sort_values(\"similarity\",ascending=False)\n",
    "        sim_books_detail = pd.merge(sim_books_detail,X_all[[\"title_book\",\"item_id_book\"]],\n",
    "                                    on=\"item_id_book\",how=\"left\")\n",
    "\n",
    "        # Add top book to recommendations dataframe\n",
    "        top_book = pd.DataFrame([sim_books_detail.loc[0]])\n",
    "        recommendations = pd.concat([recommendations,top_book],axis=0, ignore_index=True)\n",
    "    \n",
    "    print(\"Inputted films\")\n",
    "    print(movies)\n",
    "    return recommendations[\"title_book\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_reccs_cluster(user_movies:list):\n",
    "    \n",
    "    verified_movies = [movie_id for movie_id in user_movies if movie_id in X_all.item_id_movie.tolist()]\n",
    "    \n",
    "    ## Collect vectors of all inputted films and calculate average vector\n",
    "    movies_id = pd.DataFrame(verified_movies,columns=[\"item_id_movie\"])\n",
    "    movies_vectors = pd.merge(movies_id,\n",
    "                              X_vectors_movies,\n",
    "                              how=\"left\",\n",
    "                              on=\"item_id_movie\").set_index(\"item_id_movie\")\n",
    "    avg_movie_vector = pd.DataFrame([movies_vectors.mean(numeric_only=True)]).drop(columns=[\"clustering_label_bert\"])\n",
    "    all_movies_vectors = X_vectors_movies.drop(columns=[\"clustering_label_bert\"])\n",
    "    \n",
    "    ## Find cluster of nearest item (film)\n",
    "    sim_movies = cosine_similarity(all_movies_vectors,avg_movie_vector)\n",
    "    sim_movies_detail = pd.DataFrame(sim_movies,\n",
    "                                     index=all_movies_vectors.index,\n",
    "                                     columns=[\"similarity\"]).sort_values(\"similarity\",ascending=False).reset_index()\n",
    "    closest_movie_id = sim_movies_detail.loc[0].item_id_movie\n",
    "    closest_cluster = X_vectors_movies[X_vectors_movies.index == closest_movie_id].clustering_label_bert.values[0]\n",
    "    books_vectors = X_vectors_books[X_vectors_books.clustering_label_bert== closest_cluster].drop(columns=[\"clustering_label_bert\"])\n",
    "\n",
    "    ## Calculate cosine similarity\n",
    "    sim_books = cosine_similarity(books_vectors,avg_movie_vector)\n",
    "\n",
    "    ## Create summary table of books with their similarity and relevant details\n",
    "    sim_books_detail = pd.DataFrame(sim_books,index=books_vectors.index,columns=[\"similarity\"])\n",
    "    sim_books_detail = sim_books_detail.sort_values(\"similarity\",ascending=False)\n",
    "    sim_books_detail = pd.merge(sim_books_detail,X_all[[\"title_book\",\"item_id_book\"]],on=\"item_id_book\",how=\"left\")\n",
    "    \n",
    "    ## Take top 5 books and show results\n",
    "    recommendations = sim_books_detail.head(5)\n",
    "    movie_titles = pd.merge(movies_id,X_all[[\"title_movie\",\"item_id_movie\"]],how=\"inner\",on=\"item_id_movie\")\n",
    "    print(\"Inputted films\")\n",
    "    print(movie_titles.title_movie)\n",
    "    print (\"Top 5 book recommendations\")\n",
    "    return recommendations[\"title_book\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations with clusters and ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_reccs_cluster_rating(user_movies:list):\n",
    "    \n",
    "    verified_movies = [movie_id for movie_id in user_movies if movie_id in X_all.item_id_movie.tolist()]\n",
    "    \n",
    "    recommendations = pd.DataFrame(columns=[\"similarity\",\"title_book\"])\n",
    "    movies = pd.DataFrame(verified_movies,columns=[\"item_id_movie\"])\n",
    "    movies = pd.merge(movies,X_all[[\"title_movie\",\"item_id_movie\"]],on=\"item_id_movie\",how=\"left\")\n",
    "    \n",
    "    for movie_id in verified_movies:\n",
    "\n",
    "        # Obtain vectors for user-inputted film and all books.\n",
    "        movie_cluster = X_vectors_movies[X_vectors_movies.index == movie_id].clustering_label_bert.values[0]\n",
    "        movie_vector = X_vectors_movies[X_vectors_movies.index == movie_id].drop(columns=[\"clustering_label_bert\"])\n",
    "        books_vectors = X_vectors_good_books[X_vectors_books.clustering_label_bert == movie_cluster].drop(columns=[\"clustering_label_bert\"])\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        sim_books = cosine_similarity(books_vectors,movie_vector)\n",
    " \n",
    "        # Create summary table of books with their similarity and relevant details\n",
    "        sim_books_detail = pd.DataFrame(sim_books,index=books_vectors.index,columns=[\"similarity\"])\n",
    "        sim_books_detail = sim_books_detail.sort_values(\"similarity\",ascending=False)\n",
    "        sim_books_detail = pd.merge(sim_books_detail,X_all[[\"title_book\",\"item_id_book\"]],\n",
    "                                    on=\"item_id_book\",how=\"left\")\n",
    "\n",
    "        # Add top book to recommendations dataframe\n",
    "        top_book = pd.DataFrame([sim_books_detail.loc[0]])\n",
    "        recommendations = pd.concat([recommendations,top_book],axis=0, ignore_index=True)\n",
    "    \n",
    "    print(\"Inputted films\")\n",
    "    print(movies)\n",
    "    return recommendations[\"title_book\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_reccs_cluster_rating(user_movies:list):\n",
    "    \n",
    "    verified_movies = [movie_id for movie_id in user_movies if movie_id in X_all.item_id_movie.tolist()]\n",
    "    \n",
    "    ## Collect vectors of all inputted films and calculate average vector\n",
    "    movies_id = pd.DataFrame(verified_movies,columns=[\"item_id_movie\"])\n",
    "    movies_vectors = pd.merge(movies_id,\n",
    "                              X_vectors_movies,\n",
    "                              how=\"left\",\n",
    "                              on=\"item_id_movie\").set_index(\"item_id_movie\")\n",
    "    avg_movie_vector = pd.DataFrame([movies_vectors.mean(numeric_only=True)]).drop(columns=[\"clustering_label_bert\"])\n",
    "    all_movies_vectors = X_vectors_movies.drop(columns=[\"clustering_label_bert\"])\n",
    "    \n",
    "    ## Find cluster of nearest item (film)\n",
    "    sim_movies = cosine_similarity(all_movies_vectors,avg_movie_vector)\n",
    "    sim_movies_detail = pd.DataFrame(sim_movies,\n",
    "                                     index=all_movies_vectors.index,\n",
    "                                     columns=[\"similarity\"]).sort_values(\"similarity\",ascending=False).reset_index()\n",
    "    closest_movie_id = sim_movies_detail.loc[0].item_id_movie\n",
    "    closest_cluster = X_vectors_movies[X_vectors_movies.index == closest_movie_id].clustering_label_bert.values[0]\n",
    "    books_vectors = X_vectors_good_books[X_vectors_good_books.clustering_label_bert== closest_cluster].drop(columns=[\"clustering_label_bert\"])\n",
    "\n",
    "    ## Calculate cosine similarity\n",
    "    sim_books = cosine_similarity(books_vectors,avg_movie_vector)\n",
    "\n",
    "    ## Create summary table of books with their similarity and relevant details\n",
    "    sim_books_detail = pd.DataFrame(sim_books,index=books_vectors.index,columns=[\"similarity\"])\n",
    "    sim_books_detail = sim_books_detail.sort_values(\"similarity\",ascending=False)\n",
    "    sim_books_detail = pd.merge(sim_books_detail,X_all[[\"title_book\",\"item_id_book\"]],on=\"item_id_book\",how=\"left\")\n",
    "    \n",
    "    ## Take top 5 books and show results\n",
    "    recommendations = sim_books_detail.head(5)\n",
    "    movie_titles = pd.merge(movies_id,X_all[[\"title_movie\",\"item_id_movie\"]],how=\"inner\",on=\"item_id_movie\")\n",
    "    print(\"Inputted films\")\n",
    "    print(movie_titles.title_movie)\n",
    "    print (\"Top 5 book recommendations\")\n",
    "    return recommendations[\"title_book\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustrative results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local apporach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputted films\n",
      "   item_id_movie                         title_movie\n",
      "0              1                    Toy Story (1995)\n",
      "1              2                      Jumanji (1995)\n",
      "2              3             Grumpier Old Men (1995)\n",
      "3              4            Waiting to Exhale (1995)\n",
      "4              5  Father of the Bride Part II (1995)\n",
      "5              6                         Heat (1995)\n",
      "6              7                      Sabrina (1995)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                  Waiting\n",
       "1     The Serpent of Venice (The Fool, #2)\n",
       "2                                 Cranford\n",
       "3            White Hot (Hidden Legacy, #2)\n",
       "4    Road to Nowhere (Road to Nowhere, #1)\n",
       "5     Field of Prey (Lucas Davenport, #24)\n",
       "6                  Devoured (Devoured, #1)\n",
       "Name: title_book, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_local_reccs([1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputted films\n",
      "   item_id_movie                         title_movie\n",
      "0              1                    Toy Story (1995)\n",
      "1              2                      Jumanji (1995)\n",
      "2              3             Grumpier Old Men (1995)\n",
      "3              4            Waiting to Exhale (1995)\n",
      "4              5  Father of the Bride Part II (1995)\n",
      "5              6                         Heat (1995)\n",
      "6              7                      Sabrina (1995)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                              Waiting\n",
       "1    The Hunger Games Trilogy Boxset (The Hunger Ga...\n",
       "2                    Feral Sins (The Phoenix Pack, #1)\n",
       "3                        White Hot (Hidden Legacy, #2)\n",
       "4                Road to Nowhere (Road to Nowhere, #1)\n",
       "5                 Field of Prey (Lucas Davenport, #24)\n",
       "6                    I Wish You Were Mine (Oxford, #2)\n",
       "Name: title_book, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_local_reccs_rating([1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_local_reccs_cluster([1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_local_reccs_cluster_rating([1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputted films\n",
      "0                      Toy Story (1995)\n",
      "1                        Jumanji (1995)\n",
      "2               Grumpier Old Men (1995)\n",
      "3              Waiting to Exhale (1995)\n",
      "4    Father of the Bride Part II (1995)\n",
      "5                           Heat (1995)\n",
      "6                        Sabrina (1995)\n",
      "Name: title_movie, dtype: object\n",
      "Top 5 book recommendations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0           Ghost World\n",
       "1             Gone Girl\n",
       "2              Cranford\n",
       "3    The Stepford Wives\n",
       "4               Flipped\n",
       "Name: title_book, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_global_reccs([1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputted films\n",
      "0                      Toy Story (1995)\n",
      "1                        Jumanji (1995)\n",
      "2               Grumpier Old Men (1995)\n",
      "3              Waiting to Exhale (1995)\n",
      "4    Father of the Bride Part II (1995)\n",
      "5                           Heat (1995)\n",
      "6                        Sabrina (1995)\n",
      "Name: title_movie, dtype: object\n",
      "Top 5 book recommendations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                Flipped\n",
       "1                        Trust Your Eyes\n",
       "2    Hollywood Dirt (Hollywood Dirt, #1)\n",
       "3                             Tiger Lily\n",
       "4       Sustained (The Legal Briefs, #2)\n",
       "Name: title_book, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_global_reccs_rating([1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputted films\n",
      "0                      Toy Story (1995)\n",
      "1                        Jumanji (1995)\n",
      "2               Grumpier Old Men (1995)\n",
      "3              Waiting to Exhale (1995)\n",
      "4    Father of the Bride Part II (1995)\n",
      "5                           Heat (1995)\n",
      "6                        Sabrina (1995)\n",
      "Name: title_movie, dtype: object\n",
      "Top 5 book recommendations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Straight Man\n",
       "Name: title_book, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_global_reccs_cluster([1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputted films\n",
      "0                      Toy Story (1995)\n",
      "1                        Jumanji (1995)\n",
      "2               Grumpier Old Men (1995)\n",
      "3              Waiting to Exhale (1995)\n",
      "4    Father of the Bride Part II (1995)\n",
      "5                           Heat (1995)\n",
      "6                        Sabrina (1995)\n",
      "Name: title_movie, dtype: object\n",
      "Top 5 book recommendations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Straight Man\n",
       "Name: title_book, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_global_reccs_cluster_rating([1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification of good book recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_reccs_movies(user_books:list):\n",
    "    \n",
    "    verified_books = [book_id for book_id in user_books if book_id in X_all.item_id_book.tolist()]\n",
    "    \n",
    "    recommendations = pd.DataFrame(columns=[\"similarity\",\"title_movie\"])\n",
    "    books = pd.DataFrame(verified_books,columns=[\"item_id_book\"])\n",
    "    books = pd.merge(books,X_all[[\"title_book\",\"item_id_book\"]],on=\"item_id_book\",how=\"left\")\n",
    "    \n",
    "    for book_id in verified_books:\n",
    "\n",
    "        # Obtain vectors for user-inputted book\n",
    "        book_vector = X_vectors_books[X_vectors_books.index == book_id].drop(columns=[\"clustering_label_bert\"])\n",
    "        movies_vectors = X_vectors_movies.drop(columns=[\"clustering_label_bert\"])\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        sim_movies = cosine_similarity(movies_vectors,book_vector)\n",
    " \n",
    "        # Create summary table of movie with their similarity and relevant details\n",
    "        sim_movies_detail = pd.DataFrame(sim_movies,index=movies_vectors.index,columns=[\"similarity\"])\n",
    "        sim_movies_detail = sim_movies_detail.sort_values(\"similarity\",ascending=False)\n",
    "        sim_movies_detail = pd.merge(sim_movies_detail,X_all[[\"title_movie\",\"item_id_movie\"]],\n",
    "                                    on=\"item_id_movie\",how=\"left\")\n",
    "\n",
    "        # Add top movie to recommendations dataframe\n",
    "        top_movie = pd.DataFrame([sim_movies_detail.loc[0]])\n",
    "        recommendations = pd.concat([recommendations,top_movie],axis=0, ignore_index=True)\n",
    "    \n",
    "    print(\"Inputted films\")\n",
    "    print(books)\n",
    "    return recommendations[\"title_movie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_reccs_movies(user_books:list):\n",
    "    \n",
    "    verified_books = [book_id for book_id in user_books if book_id in X_all.item_id_book.tolist()]\n",
    "    \n",
    "    ## Collect vectors of all inputted books and calculate average vector\n",
    "    books_id = pd.DataFrame(verified_books,columns=[\"item_id_book\"])\n",
    "    books_vectors = pd.merge(books_id,\n",
    "                              X_vectors_books,\n",
    "                              how=\"left\",\n",
    "                              on=\"item_id_book\").set_index(\"item_id_book\")\n",
    "    avg_book_vector = pd.DataFrame([books_vectors.mean(numeric_only=True)]).drop(columns=[\"clustering_label_bert\"])\n",
    "    all_books_vectors = X_vectors_books.drop(columns=[\"clustering_label_bert\"])\n",
    "    \n",
    "    movies_vectors = X_vectors_movies.drop(columns=[\"clustering_label_bert\"])\n",
    "\n",
    "    ## Calculate cosine similarity\n",
    "    sim_movies = cosine_similarity(movies_vectors,avg_book_vector)\n",
    "\n",
    "    ## Create summary table of books with their similarity and relevant details\n",
    "    sim_movies_detail = pd.DataFrame(sim_movies,index=movies_vectors.index,columns=[\"similarity\"])\n",
    "    sim_movies_detail = sim_movies_detail.sort_values(\"similarity\",ascending=False)\n",
    "    sim_movies_detail = pd.merge(sim_movies_detail,X_all[[\"title_movie\",\"item_id_movie\"]],on=\"item_id_movie\",how=\"left\")\n",
    "    \n",
    "    ## Take top 5 books and show results\n",
    "    recommendations = sim_movies_detail.head(5)\n",
    "    book_titles = pd.merge(books_id,X_all[[\"title_book\",\"item_id_book\"]],how=\"inner\",on=\"item_id_book\")\n",
    "    print(\"Inputted books\")\n",
    "    print(book_titles.title_book)\n",
    "    print (\"Top 5 movie recommendations\")\n",
    "    return recommendations[\"title_movie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books(keyword):\n",
    "    books = pd.DataFrame(X_all[X_all.is_movie==0].title_book).sort_values(by=[\"title_book\"])\n",
    "    books = books.title_book.to_list()\n",
    "    return [book for book in books if keyword in book]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_ids(books):\n",
    "    book_ids = []\n",
    "    for book in books:\n",
    "        if book in X_all.title_book.tolist():\n",
    "            book_id = X_all[X_all.title_book == book].item_id_book.values[0]\n",
    "            book_ids.append(book_id)\n",
    "    return book_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1984', 'Animal Farm / 1984']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_books(\"1984\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_books = [\"1984\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_books_ids = get_books_ids(example_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputted films\n",
      "   item_id_book title_book\n",
      "0      153313.0       1984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Left Behind: The Movie (2000)\n",
       "Name: title_movie, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_local_reccs_movies(example_books_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputted books\n",
      "0    1984\n",
      "Name: title_book, dtype: object\n",
      "Top 5 movie recommendations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0               Left Behind: The Movie (2000)\n",
       "1    Forest of the Gods (Dievu miskas) (2005)\n",
       "2                           The Chosen (2016)\n",
       "3                             Timeline (2003)\n",
       "4                  Midnight's Children (2012)\n",
       "Name: title_movie, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_global_reccs_movies(example_books_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
